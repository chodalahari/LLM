# -*- coding: utf-8 -*-
"""textgenerativemodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12aWU_MQgcFQKfebis4jXu5T2hSY_DQCV
"""

from transformers import AutoTokenizer, AutoModelForCausalLM

# Load pretrained model and tokenizer
tokenizer = AutoTokenizer.from_pretrained("gpt2")
model = AutoModelForCausalLM.from_pretrained("gpt2")

# Input prompt
prompt = "Artificial intelligence is"

# Tokenize input
inputs = tokenizer(prompt, return_tensors="pt")

# Generate text
outputs = model.generate(
    **inputs,
    max_length=50,
    do_sample=True,
    temperature=0.7
)

# Decode output
generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(generated_text)

