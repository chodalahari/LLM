{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "vocab_size = 1000\n",
        "max_len = 20\n",
        "\n",
        "# Load IMDb dataset\n",
        "(X_train, _), _ = imdb.load_data(num_words=vocab_size)\n",
        "X_train = pad_sequences(X_train[:1000], maxlen=max_len)\n",
        "\n",
        "# Dummy entity labels (0 = Non-Entity, 1 = Entity)\n",
        "y_train = np.random.randint(0, 2, size=(X_train.shape[0], max_len))\n",
        "\n",
        "# Build NER model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 64, input_length=max_len),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, epochs=2, batch_size=32)\n",
        "\n",
        "# ---- OUTPUT PART ----\n",
        "sample = X_train[0].reshape(1, max_len)\n",
        "prediction = model.predict(sample)\n",
        "\n",
        "predicted_labels = np.argmax(prediction, axis=-1)\n",
        "\n",
        "print(\"\\nNamed Entity Recognition Output:\")\n",
        "for i, label in enumerate(predicted_labels[0]):\n",
        "    print(f\"Token {i+1}: Entity\" if label == 1 else f\"Token {i+1}: Non-Entity\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRuv2PGjNfsJ",
        "outputId": "69e9bbf4-6bec-4ca2-b2e7-f44e17a69033"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.4979 - loss: 0.6932\n",
            "Epoch 2/2\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5331 - loss: 0.6917\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
            "\n",
            "Named Entity Recognition Output:\n",
            "Token 1: Entity\n",
            "Token 2: Entity\n",
            "Token 3: Entity\n",
            "Token 4: Entity\n",
            "Token 5: Non-Entity\n",
            "Token 6: Non-Entity\n",
            "Token 7: Non-Entity\n",
            "Token 8: Non-Entity\n",
            "Token 9: Entity\n",
            "Token 10: Entity\n",
            "Token 11: Entity\n",
            "Token 12: Entity\n",
            "Token 13: Entity\n",
            "Token 14: Entity\n",
            "Token 15: Entity\n",
            "Token 16: Entity\n",
            "Token 17: Entity\n",
            "Token 18: Entity\n",
            "Token 19: Entity\n",
            "Token 20: Entity\n"
          ]
        }
      ]
    }
  ]
}